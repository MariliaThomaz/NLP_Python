{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9UAmudU8K7SEli8apG98U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariliaThomaz/NLP_Python/blob/main/spacy_aula01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cODuHfWIoTpT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a1ff0ae-da86-4252-f889-7f70b23d6f35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy==3.2.0 in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (8.0.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (0.7.10)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (0.4.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (0.10.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.3.5->spacy==3.2.0) (6.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy==3.2.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.0) (2023.7.22)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.5.0,>=0.3.0->spacy==3.2.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy==3.2.0) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "# estalando uma nova versão spacy\n",
        "\n",
        "!pip install -U spacy==3.2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1EH02r7upIL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# baixar um modelo pré treinado\n",
        "!python -m spacy download 'pt_core_news_lg'"
      ],
      "metadata": {
        "id": "fnVIpCkYpJ2w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f3c17ac-8fa2-4b42-d54a-3650052407ce"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-25 16:52:18.177556: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-25 16:52:19.762074: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[33mDEPRECATION: https://github.com/explosion/spacy-models/releases/download/pt_core_news_lg-3.2.0/pt_core_news_lg-3.2.0-py3-none-any.whl#egg=pt_core_news_lg==3.2.0 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting pt-core-news-lg==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_lg-3.2.0/pt_core_news_lg-3.2.0-py3-none-any.whl (577.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m577.4/577.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from pt-core-news-lg==3.2.0) (3.2.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (8.0.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (0.7.10)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (0.4.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (0.10.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (6.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (2023.7.22)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->pt-core-news-lg==3.2.0) (2.1.3)\n",
            "Installing collected packages: pt-core-news-lg\n",
            "Successfully installed pt-core-news-lg-3.2.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('pt_core_news_lg')"
      ],
      "metadata": {
        "id": "8ToUNugdpKH4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(nlp))"
      ],
      "metadata": {
        "id": "xGR-dw1ipKaR",
        "outputId": "ee41853e-b875-457c-9937-8868de75aa4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'spacy.lang.pt.Portuguese'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vendo pipeline padrão\n",
        "print(nlp.pipe_names)"
      ],
      "metadata": {
        "id": "FH6c_ghIpKde",
        "outputId": "f28efdcf-58c7-48e4-e509-ba4239258332",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tok2vec', 'morphologizer', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# criando um documento, criando um objeto Dorq no Spacy\n",
        "documeto = nlp(\"Marilia esta, mais 60% da formação do estagio. O estudos são sempre hequiquesedor, Marilia  está  muito feliz\")"
      ],
      "metadata": {
        "id": "wfTMss5rpKg4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vendo o tamanho do vocabulário do documento\n",
        "len(documeto.vocab)"
      ],
      "metadata": {
        "id": "hzlS17NqpKkv",
        "outputId": "c18b1612-e5c1-470d-f91d-140af9c3ce3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "367"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(documeto)"
      ],
      "metadata": {
        "id": "RaqOwSjl1N_4",
        "outputId": "c2d17b7b-c1ae-448c-e646-ca8fbd335445",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#toker rechts únicos, é como se classificasse uma palavra com o número\n",
        "#token  ele  é  produzido altomaticamaticamente\n",
        "#pode ver  alfa numerrtico  ele  tem varisa proedade"
      ],
      "metadata": {
        "id": "rlUsbcVkO0_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in documeto:\n",
        "  print(token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq31jh9PP_BT",
        "outputId": "f2de4f1c-16e4-4f58-8692-8f875cf6555d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Marilia\n",
            "esta\n",
            ",\n",
            "mais\n",
            "60\n",
            "%\n",
            "da\n",
            "formação\n",
            "do\n",
            "estagio\n",
            ".\n",
            "O\n",
            "estudos\n",
            "são\n",
            "sempre\n",
            "hequiquesedor\n",
            ",\n",
            "Marilia\n",
            " \n",
            "está\n",
            " \n",
            "muito\n",
            "feliz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# token pelo indexi\n",
        "documeto[3]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-TWVAEoQACu",
        "outputId": "61bb8c3e-ad59-4daf-9b16-0e314c208f90"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mais"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pegar o intervalo\n",
        "documeto[3:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15drB-bsQAPw",
        "outputId": "dee081e3-0546-4a58-fb58-454fa1f5e898"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mais 60"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vendo a quantidade de token\n",
        "len(documeto)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69EpbhcnP_UX",
        "outputId": "97cf341f-5bc7-4e52-a021-51ea04995ff3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Todos  os Tokens: \\n \", [token.text for token in documeto])\n",
        "print(\"Stop word: \\n \", [token.is_stop for token in documeto])\n",
        "print(\"Alfanumerico: \\n \", [token.is_alpha for token in documeto])\n",
        "print(\"Maisculo: \\n \", [token.is_upper for token in documeto])\n",
        "print(\"Pontuação: \\n \", [token.is_punct for token in documeto])\n",
        "print(\"Numero: \\n \", [token.like_num for token in documeto])\n",
        "print(\"Sentença Inicial: \\n \", [token.is_sent_start for token in documeto])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAgwr6dvP_l5",
        "outputId": "0d2db668-0b1c-4878-f4e1-2684573fbd49"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Todos  os Tokens: \n",
            "  ['Marilia', 'esta', ',', 'mais', '60', '%', 'da', 'formação', 'do', 'estagio', '.', 'O', 'estudos', 'são', 'sempre', 'hequiquesedor', ',', 'Marilia', ' ', 'está', ' ', 'muito', 'feliz']\n",
            "Stop word: \n",
            "  [False, True, False, True, False, False, True, False, True, False, False, True, False, True, True, False, False, False, False, True, False, True, False]\n",
            "Alfanumerico: \n",
            "  [True, True, False, True, False, False, True, True, True, True, False, True, True, True, True, True, False, True, False, True, False, True, True]\n",
            "Maisculo: \n",
            "  [False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False]\n",
            "Pontuação: \n",
            "  [False, False, True, False, False, True, False, False, False, False, True, False, False, False, False, False, True, False, False, False, False, False, False]\n",
            "Numero: \n",
            "  [False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
            "Sentença Inicial: \n",
            "  [True, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Todos  os Tokens: \\n \", [token.text for token in documeto])\n",
        "print(\"Formato: \\n \", [token.shape_ for token in documeto])\n",
        "#  seria interessante para caso  de processar dados no jeito natural"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeFAQom6fWTM",
        "outputId": "c2a357fb-4f5a-45e3-b4be-b15fd2647d41"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Todos  os Tokens: \n",
            "  ['Marilia', 'esta', ',', 'mais', '60', '%', 'da', 'formação', 'do', 'estagio', '.', 'O', 'estudos', 'são', 'sempre', 'hequiquesedor', ',', 'Marilia', ' ', 'está', ' ', 'muito', 'feliz']\n",
            "Formato: \n",
            "  ['Xxxxx', 'xxxx', ',', 'xxxx', 'dd', '%', 'xx', 'xxxx', 'xx', 'xxxx', '.', 'X', 'xxxx', 'xxx', 'xxxx', 'xxxx', ',', 'Xxxxx', ' ', 'xxxx', ' ', 'xxxx', 'xxxx']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# procurando elementos documentos projeto Doq\n",
        "for token  in documeto:\n",
        "  if token.like_num:\n",
        "    print(\"Numero encontrado: \", token.text)\n",
        "  if token.is_punct:\n",
        "    print(\"Pontuação encontrada: \", token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZCSbJd1fVrt",
        "outputId": "92aa3554-6573-4043-f189-ff8e45a38a93"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pontuação encontrada:  ,\n",
            "Numero encontrado:  60\n",
            "Pontuação encontrada:  %\n",
            "Pontuação encontrada:  .\n",
            "Pontuação encontrada:  ,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in documeto:\n",
        "  print(token.text, \"-\",  token.pos, \"-\", token.dep,\"-\", token.lemma_, \"-\", token.shape_ )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBtgr7ZwiQdY",
        "outputId": "8eceb692-35d2-481c-e640-ec575e7d3845"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Marilia - 96 - 8206900633647566924 - Marilia - Xxxxx\n",
            "esta - 96 - 17772752594865228322 - este - xxxx\n",
            ", - 97 - 445 - , - ,\n",
            "mais - 86 - 400 - mais - xxxx\n",
            "60 - 93 - 12837356684637874264 - 60 - dd\n",
            "% - 99 - 403 - % - %\n",
            "da - 85 - 8110129090154140942 - da - xx\n",
            "formação - 92 - 426 - formação - xxxx\n",
            "do - 85 - 8110129090154140942 - do - xx\n",
            "estagio - 96 - 426 - estagiar - xxxx\n",
            ". - 97 - 445 - . - .\n",
            "O - 90 - 415 - O - X\n",
            "estudos - 92 - 429 - estudo - xxxx\n",
            "são - 87 - 411 - ser - xxx\n",
            "sempre - 86 - 400 - sempre - xxxx\n",
            "hequiquesedor - 86 - 8206900633647566924 - hequiquesedor - xxxx\n",
            ", - 97 - 445 - , - ,\n",
            "Marilia - 96 - 429 - Marilia - Xxxxx\n",
            "  - 103 - 414 -   -  \n",
            "está - 87 - 411 - estar - xxxx\n",
            "  - 103 - 414 -   -  \n",
            "muito - 86 - 400 - muito - xxxx\n",
            "feliz - 84 - 402 - feliz - xxxx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a morfologia  das palavras estuda\n",
        "for token in documeto:\n",
        "  print(token.text, \"-\", token.morph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDLgA8RyiQpA",
        "outputId": "78de9a0a-c64e-4764-fa1a-033b2300a3c7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Marilia - Gender=Fem|Number=Sing\n",
            "esta - Number=Sing\n",
            ", - \n",
            "mais - \n",
            "60 - NumType=Card\n",
            "% - \n",
            "da - Definite=Def|Gender=Fem|Number=Sing|PronType=Art\n",
            "formação - Gender=Fem|Number=Sing\n",
            "do - Definite=Def|Gender=Masc|Number=Sing|PronType=Art\n",
            "estagio - Gender=Masc|Number=Sing\n",
            ". - \n",
            "O - Definite=Def|Gender=Masc|Number=Sing|PronType=Art\n",
            "estudos - Gender=Masc|Number=Plur\n",
            "são - Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin\n",
            "sempre - \n",
            "hequiquesedor - \n",
            ", - \n",
            "Marilia - Gender=Fem|Number=Sing\n",
            "  - \n",
            "está - Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
            "  - \n",
            "muito - \n",
            "feliz - Gender=Masc|Number=Sing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# essa morfologia, vem mais detalhada"
      ],
      "metadata": {
        "id": "0iPNwBeukgPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in documeto:\n",
        "  print(token.text, \"-\", token.tag_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZqXQXGmk31Z",
        "outputId": "15f23b0f-fa8a-4213-8da2-425c6c4f100d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Marilia - PROPN\n",
            "esta - PROPN\n",
            ", - PUNCT\n",
            "mais - ADV\n",
            "60 - NUM\n",
            "% - SYM\n",
            "da - ADP\n",
            "formação - NOUN\n",
            "do - ADP\n",
            "estagio - PROPN\n",
            ". - PUNCT\n",
            "O - DET\n",
            "estudos - NOUN\n",
            "são - AUX\n",
            "sempre - ADV\n",
            "hequiquesedor - ADV\n",
            ", - PUNCT\n",
            "Marilia - PROPN\n",
            "  - SPACE\n",
            "está - AUX\n",
            "  - SPACE\n",
            "muito - ADV\n",
            "feliz - ADJ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# procurando as entidades nomeadas\n",
        "for ent in documeto.ents:\n",
        "  print(ent.text, \"-\", ent.label_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1McjUfi_niBI",
        "outputId": "d17067be-a56c-49aa-e4d6-4b7c1784206c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Marilia - PER\n",
            "Marilia - LOC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stop Wordes são valores semânticos ou por outra forma, valores vazios\n",
        "#stop worde é algo específico do idioma\n",
        "for token in documeto:\n",
        "  if token.is_stop:\n",
        "     print(\"Stop word: \", token.text)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLnOaNKWniUt",
        "outputId": "f8ad98a3-6f95-4a1a-e99c-b499873aa510"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop word:  esta\n",
            "Stop word:  mais\n",
            "Stop word:  da\n",
            "Stop word:  do\n",
            "Stop word:  O\n",
            "Stop word:  são\n",
            "Stop word:  sempre\n",
            "Stop word:  está\n",
            "Stop word:  muito\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#vendo qual são as Stop Wordes que o Spacy está  usando\n",
        "for word in nlp.Defaults.stop_words:\n",
        "  print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRwuonlhniof",
        "outputId": "ce2907f4-ccc5-481f-ccfd-d62896eb4c13"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elas\n",
            "seus\n",
            "foi\n",
            "muitos\n",
            "aos\n",
            "estas\n",
            "eles\n",
            "sexto\n",
            "coisa\n",
            "vós\n",
            "dar\n",
            "demais\n",
            "além\n",
            "caminho\n",
            "cujo\n",
            "ali\n",
            "num\n",
            "das\n",
            "tu\n",
            "fazia\n",
            "querem\n",
            "eventual\n",
            "cima\n",
            "conhecida\n",
            "alguns\n",
            "põe\n",
            "sim\n",
            "são\n",
            "vêm\n",
            "ir\n",
            "por\n",
            "desde\n",
            "através\n",
            "inicio\n",
            "já\n",
            "essas\n",
            "todo\n",
            "fomos\n",
            "todas\n",
            "deste\n",
            "algumas\n",
            "vos\n",
            "estar\n",
            "nenhuma\n",
            "tentei\n",
            "vossas\n",
            "talvez\n",
            "nova\n",
            "a\n",
            "temos\n",
            "até\n",
            "suas\n",
            "sabe\n",
            "zero\n",
            "conhecido\n",
            "lá\n",
            "daquele\n",
            "sois\n",
            "aí\n",
            "sete\n",
            "tipo\n",
            "pegar\n",
            "vosso\n",
            "onde\n",
            "parte\n",
            "com\n",
            "quinze\n",
            "pontos\n",
            "fostes\n",
            "meses\n",
            "duas\n",
            "esses\n",
            "ontem\n",
            "exemplo\n",
            "tal\n",
            "não\n",
            "numa\n",
            "seis\n",
            "aquilo\n",
            "pelo\n",
            "ademais\n",
            "próxima\n",
            "dos\n",
            "ver\n",
            "lhe\n",
            "foste\n",
            "oitavo\n",
            "aqui\n",
            "direita\n",
            "estás\n",
            "irá\n",
            "porém\n",
            "uma\n",
            "ligado\n",
            "outras\n",
            "sétimo\n",
            "povo\n",
            "dois\n",
            "estou\n",
            "sob\n",
            "somente\n",
            "apoio\n",
            "conselho\n",
            "dá\n",
            "como\n",
            "puderam\n",
            "sétima\n",
            "me\n",
            "for\n",
            "o\n",
            "porquanto\n",
            "dizem\n",
            "mesmo\n",
            "é\n",
            "aquela\n",
            "outros\n",
            "fui\n",
            "aquelas\n",
            "ele\n",
            "à\n",
            "apenas\n",
            "posição\n",
            "pela\n",
            "sem\n",
            "nossas\n",
            "essa\n",
            "és\n",
            "faço\n",
            "tanto\n",
            "portanto\n",
            "boa\n",
            "saber\n",
            "grande\n",
            "onze\n",
            "entre\n",
            "maioria\n",
            "usar\n",
            "quieta\n",
            "deverá\n",
            "quanto\n",
            "novo\n",
            "você\n",
            "nosso\n",
            "esse\n",
            "dez\n",
            "vinte\n",
            "primeiro\n",
            "quinta\n",
            "ou\n",
            "forma\n",
            "vão\n",
            "nós\n",
            "estava\n",
            "estiveram\n",
            "toda\n",
            "poderá\n",
            "somos\n",
            "e\n",
            "vens\n",
            "doze\n",
            "outra\n",
            "usa\n",
            "acerca\n",
            "devem\n",
            "segundo\n",
            "porque\n",
            "da\n",
            "sistema\n",
            "três\n",
            "apontar\n",
            "se\n",
            "números\n",
            "qual\n",
            "nossos\n",
            "debaixo\n",
            "algo\n",
            "cuja\n",
            "agora\n",
            "eu\n",
            "mês\n",
            "maior\n",
            "ora\n",
            "quarto\n",
            "porquê\n",
            "vindo\n",
            "tempo\n",
            "comprido\n",
            "no\n",
            "mas\n",
            "tudo\n",
            "comprida\n",
            "minhas\n",
            "terceiro\n",
            "vem\n",
            "fazer\n",
            "tive\n",
            "estes\n",
            "número\n",
            "máximo\n",
            "quem\n",
            "nessa\n",
            "oito\n",
            "partir\n",
            "ambos\n",
            "era\n",
            "sobre\n",
            "qualquer\n",
            "este\n",
            "nunca\n",
            "fazeis\n",
            "bom\n",
            "foram\n",
            "vinda\n",
            "dezasseis\n",
            "nove\n",
            "põem\n",
            "que\n",
            "ser\n",
            "tanta\n",
            "têm\n",
            "um\n",
            "corrente\n",
            "teus\n",
            "dezoito\n",
            "logo\n",
            "embora\n",
            "posso\n",
            "lugar\n",
            "estivestes\n",
            "muito\n",
            "deve\n",
            "assim\n",
            "seria\n",
            "nível\n",
            "fazes\n",
            "momento\n",
            "então\n",
            "naquele\n",
            "daquela\n",
            "perto\n",
            "vai\n",
            "tentaram\n",
            "estão\n",
            "poder\n",
            "todos\n",
            "favor\n",
            "também\n",
            "cedo\n",
            "aqueles\n",
            "grupo\n",
            "quer\n",
            "baixo\n",
            "sua\n",
            "diante\n",
            "possível\n",
            "tiveram\n",
            "valor\n",
            "vezes\n",
            "meus\n",
            "próximo\n",
            "sempre\n",
            "os\n",
            "mais\n",
            "podia\n",
            "ter\n",
            "longe\n",
            "tiveste\n",
            "grandes\n",
            "quarta\n",
            "fora\n",
            "catorze\n",
            "estivemos\n",
            "tentar\n",
            "esteve\n",
            "ambas\n",
            "depois\n",
            "estiveste\n",
            "parece\n",
            "sou\n",
            "desse\n",
            "quinto\n",
            "às\n",
            "teve\n",
            "estará\n",
            "dessa\n",
            "certeza\n",
            "antes\n",
            "pôde\n",
            "pois\n",
            "vossa\n",
            "vez\n",
            "umas\n",
            "vocês\n",
            "de\n",
            "certamente\n",
            "tendes\n",
            "enquanto\n",
            "contra\n",
            "veja\n",
            "após\n",
            "pouca\n",
            "segunda\n",
            "cá\n",
            "minha\n",
            "isto\n",
            "iniciar\n",
            "dentro\n",
            "próprio\n",
            "tivestes\n",
            "está\n",
            "quando\n",
            "estive\n",
            "treze\n",
            "tem\n",
            "meio\n",
            "último\n",
            "quê\n",
            "na\n",
            "para\n",
            "nesta\n",
            "vossos\n",
            "cinco\n",
            "tua\n",
            "nossa\n",
            "vais\n",
            "quero\n",
            "naquela\n",
            "custa\n",
            "uns\n",
            "pelas\n",
            "obrigada\n",
            "dão\n",
            "primeira\n",
            "fez\n",
            "só\n",
            "te\n",
            "ao\n",
            "tivemos\n",
            "oitava\n",
            "mil\n",
            "disso\n",
            "tente\n",
            "des\n",
            "dizer\n",
            "dezanove\n",
            "tuas\n",
            "quieto\n",
            "ainda\n",
            "fim\n",
            "atrás\n",
            "lado\n",
            "tens\n",
            "nuns\n",
            "adeus\n",
            "questão\n",
            "apoia\n",
            "inclusive\n",
            "contudo\n",
            "nos\n",
            "quais\n",
            "maiorias\n",
            "nas\n",
            "teu\n",
            "estado\n",
            "relação\n",
            "bastante\n",
            "fará\n",
            "menor\n",
            "sexta\n",
            "mal\n",
            "fazem\n",
            "local\n",
            "desta\n",
            "seu\n",
            "tais\n",
            "nem\n",
            "diz\n",
            "do\n",
            "tarde\n",
            "possivelmente\n",
            "tão\n",
            "neste\n",
            "quatro\n",
            "fazemos\n",
            "falta\n",
            "faz\n",
            "nada\n",
            "meu\n",
            "cento\n",
            "pelos\n",
            "as\n",
            "pouco\n",
            "geral\n",
            "menos\n",
            "obrigado\n",
            "final\n",
            "bem\n",
            "sei\n",
            "esta\n",
            "tenho\n",
            "aquele\n",
            "ela\n",
            "podem\n",
            "em\n",
            "terceira\n",
            "nesse\n",
            "ponto\n",
            "cada\n",
            "vários\n",
            "breve\n",
            "pode\n",
            "isso\n",
            "dezassete\n",
            "área\n",
            "novos\n",
            "novas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# você também pode adicionar um stop Word\n",
        "nlp.Defaults.stop_words.add(\"eita\")\n",
        "nlp.vocab['eita'].is_stop = True"
      ],
      "metadata": {
        "id": "nYVaM7jZk4JD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.vocab['eita'].is_stop = True"
      ],
      "metadata": {
        "id": "dLHTI1mQrQyE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criando uma lista com todos os token para  poder  remover  stop word\n",
        "token_lista = []\n",
        "for token in documeto:\n",
        "  token_lista.append(token.text)\n",
        "\n",
        "stop_lista =[]\n",
        "for words in nlp.Defaults.stop_words:\n",
        "  stop_lista.append(word)\n",
        "\n",
        "semstop = [word for word in token_lista if not word in stop_lista]\n",
        "\n",
        "print(documeto.text)\n",
        "print(semstop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcQIntv1rkMW",
        "outputId": "9c5117ec-2032-4958-ad3c-51ebb1070b9f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Marilia esta, mais 60% da formação do estagio. O estudos são sempre hequiquesedor, Marilia  está  muito feliz\n",
            "['Marilia', 'esta', ',', 'mais', '60', '%', 'da', 'formação', 'do', 'estagio', '.', 'O', 'estudos', 'são', 'sempre', 'hequiquesedor', ',', 'Marilia', ' ', 'está', ' ', 'muito', 'feliz']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DOWaXhItrkce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hUTP4bG8rkln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UzeAPCD-sMf8"
      }
    }
  ]
}